{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPcla8UgKRbkv/aApIzFOB0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/intraprasart/Quantum-Perceptron-Machine-Learning-using-Nitch-Fitness-Operator/blob/main/3_Classes_with_LostFn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5y2KlrMi3CSe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdc7e462"
      },
      "source": [
        "# 3 Classes Classification\n",
        "\n",
        "This notebook aims to demonstrate a 3-class classification problem. It will involve data generation, model training, and evaluation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6b56affe"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "139a758a"
      },
      "source": [
        "## 1. Data Generation\n",
        "\n",
        "We will create a synthetic dataset with 3 distinct classes using `make_blobs`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66069bc5"
      },
      "source": [
        "# Generate synthetic data for 3 classes\n",
        "n_samples = 1500\n",
        "n_features = 2\n",
        "n_classes = 3\n",
        "random_state = 42\n",
        "\n",
        "X, y = make_blobs(n_samples=n_samples, n_features=n_features, centers=n_classes, cluster_std=1.0, random_state=random_state)\n",
        "\n",
        "print(f\"Shape of X: {X.shape}\")\n",
        "print(f\"Shape of y: {y.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de253a8d"
      },
      "source": [
        "### Visualize the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03dd59c1"
      },
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', s=50, alpha=0.8)\n",
        "plt.title('Synthetic 3-Class Data')\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "plt.colorbar(label='Class')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7be60321"
      },
      "source": [
        "## 2. Data Preprocessing\n",
        "\n",
        "Split the data into training and testing sets, and then scale the features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5c51a1c"
      },
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random_state, stratify=y)\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d812103c"
      },
      "source": [
        "### Feature Scaling\n",
        "\n",
        "Scaling is important for neural networks to ensure that features with larger values do not dominate the learning process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8a85d5c"
      },
      "source": [
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"Features scaled successfully.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "851ede4b"
      },
      "source": [
        "## 3. Model Training\n",
        "\n",
        "We will use a Multi-layer Perceptron (MLP) Classifier from scikit-learn to train a neural network model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c315424f"
      },
      "source": [
        "# Initialize the MLP Classifier\n",
        "# hidden_layer_sizes: tuple, length = n_layers - 2, default (100,)\n",
        "# The ith element represents the number of neurons in the ith hidden layer.\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(10, 10), max_iter=1000, random_state=random_state, activation='relu', solver='adam')\n",
        "\n",
        "# Train the model\n",
        "print(\"Training the MLP model...\")\n",
        "mlp.fit(X_train_scaled, y_train)\n",
        "print(\"Model training complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75ef007b"
      },
      "source": [
        "## 4. Model Evaluation\n",
        "\n",
        "Evaluate the trained model using accuracy, classification report, and a confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1c75434e"
      },
      "source": [
        "# Make predictions on the test set\n",
        "y_pred = mlp.predict(X_test_scaled)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Display classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12b920d9"
      },
      "source": [
        "### Confusion Matrix\n",
        "\n",
        "A confusion matrix provides a detailed breakdown of correct and incorrect classifications for each class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "738ea9dc"
      },
      "source": [
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "            xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2baf8ce5"
      },
      "source": [
        "### Decision Boundary Visualization\n",
        "\n",
        "Visualize the decision boundaries learned by the MLP classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07f88fe5"
      },
      "source": [
        "def plot_decision_boundary(X, y, model, title):\n",
        "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
        "                         np.arange(y_min, y_max, 0.02))\n",
        "\n",
        "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.contourf(xx, yy, Z, alpha=0.4, cmap='viridis')\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y, s=20, edgecolor='k', cmap='viridis')\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Feature 1')\n",
        "    plt.ylabel('Feature 2')\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54250f5c"
      },
      "source": [
        "# Since the model was trained on scaled data, we need to apply the scaler to the meshgrid points\n",
        "# for visualization.\n",
        "\n",
        "# Generate meshgrid for plotting (on original scale)\n",
        "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
        "                     np.arange(y_min, y_max, 0.02))\n",
        "\n",
        "# Scale the meshgrid points\n",
        "Z_scaled = scaler.transform(np.c_[xx.ravel(), yy.ravel()])\n",
        "\n",
        "# Predict class for each point in the scaled meshgrid\n",
        "Z = mlp.predict(Z_scaled)\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.contourf(xx, yy, Z, alpha=0.4, cmap='viridis')\n",
        "plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, s=20, edgecolor='k', cmap='viridis')\n",
        "plt.title('MLP Classifier Decision Boundary on Test Data')\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "plt.colorbar(label='Class')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2f6d379"
      },
      "source": [
        "## 5. Conclusion\n",
        "\n",
        "This notebook demonstrated a simple 3-class classification problem using a Multi-layer Perceptron (MLP) neural network.\n",
        "\n",
        "Key steps involved:\n",
        "1.  **Data Generation**: Created a synthetic dataset with three distinct classes.\n",
        "2.  **Data Preprocessing**: Split the data into training and testing sets and scaled the features using `StandardScaler`.\n",
        "3.  **Model Training**: Trained an `MLPClassifier` with a specified hidden layer structure and activation function.\n",
        "4.  **Model Evaluation**: Evaluated the model's performance using accuracy, classification report, and a confusion matrix.\n",
        "5.  **Visualization**: Visualized the decision boundary learned by the MLP model.\n",
        "\n",
        "The model achieved a high accuracy, indicating its ability to effectively classify the three distinct classes in the synthetic dataset."
      ]
    }
  ]
}